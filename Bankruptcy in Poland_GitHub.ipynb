{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b65215-f7af-40a6-b44c-6ad76793e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b81018-bc8d-4251-9cb6-cd193a1315fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "df = pd.read_csv(r\"C:\\Users\\HP\\Desktop\\archive\\data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f7cbd-ba3a-40cd-99c7-56477ee0e685",
   "metadata": {},
   "source": [
    "# Exploring and Wrangling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185a4bab-8897-4d10-94a9-8b37ea40d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the data\n",
    "# df.head()\n",
    "df.shape\n",
    "\n",
    "# Check for missing values\n",
    "# df.isnull().sum()\n",
    "\n",
    "# Summary statistics\n",
    "# df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80068fb3-e0ca-45e1-a30e-b074d8055d4d",
   "metadata": {},
   "source": [
    "We have 43405 rows and 66 columns, 5 years worth of data, we only take the data from the 5th year for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95190336-fc81-4e5a-912b-184f87aface5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking dataset from the 5th year only\n",
    "df = df[df[\"year\"] == 5]\n",
    "\n",
    "# Droping the year column after taking the data from year 5 only\n",
    "df = df.drop(columns=[\"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cfb655-660a-47d8-868d-f2f26c31c0e2",
   "metadata": {},
   "source": [
    "It seems that the class is our target, meaning class 0 means 'not bankrupt' and class 1 means 'bankrupt', so we change it to boolean data type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f55b72-b116-422d-a269-c0ef25c2f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"]= df[\"class\"].astype(bool)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab935b34-97bc-43bb-a5ec-41ccbabd0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming the index as \"company id\"\n",
    "df.index.name = 'Company_ID'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d6b46a-7552-4f22-a4a9-4fa0cf2e5d4f",
   "metadata": {},
   "source": [
    "We need to check if there are any missing data in the dataset, so we create a Series where the index contains the name of the columns in df and the values are the number of NaNs in each column. We assign the result to nans_by_col. Neither the Series itself nor its index require a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4046443-25c6-4e07-87e9-de087047e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nans_by_col = df.isna().sum()\n",
    "print(\"nans_by_col shape:\", nans_by_col.shape)\n",
    "nans_by_col.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee8cb1-8166-424f-8c9a-933c91612b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check if the data imbalanced by creating a bar chart that shows shows it\n",
    "df[\"class\"].value_counts(normalize=True).plot(\n",
    "    kind=\"bar\",\n",
    "    xlabel=\"Bankrupt\",\n",
    "    ylabel=\"Frequency\",\n",
    "    title=\"Class Balance\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768972a-4b20-43a8-a205-1db8b07e78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data into our feature matrix X and target vector y.Our target is \"class\"\n",
    "target = \"class\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53561fef-1331-40cd-a5d7-46ff0e47a329",
   "metadata": {},
   "source": [
    "We divide our dataset into training and test sets using a randomized split.The test set would be 20% of our data. We set random_state to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c74d7d-0f34-445a-86f7-9732028c9df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3bdf1e-9b7b-4561-9340-f49f103f7c9a",
   "metadata": {},
   "source": [
    "For resampling, we create a new feature matrix X_train_over and target vector y_train_over by performing random over-sampling on the training data.we set the random_state to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d69af-ec19-4613-9b87-4dcc14bf0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = over_sampler.fit_resample(X_train, y_train)\n",
    "print(\"X_train_over shape:\", X_train_over.shape)\n",
    "X_train_over.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c9b1c6-7dd8-4d90-8376-22ad255826ba",
   "metadata": {},
   "source": [
    "We proceed to Building the Model by first iterating. We create a classifier \"clf \"that can be trained on (X_train_over, y_train_over). Using an ensemble predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac0158-81f7-4f65-85e0-b01ce0472b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(SimpleImputer(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750e443-3d0a-4dc8-995e-caa7d859520b",
   "metadata": {},
   "source": [
    "Remember while we're doing this that we only want to be looking at the positive class. Here, the positive class is the one where the companies really did go bankrupt\n",
    "\n",
    "Next we perform cross-validation with our classifier, using the over-sampled training data. We want five folds, so set cv to 5. We also want to speed up training, to set n_jobs to -1, We use our CV scores to evaluate different classifiers. Choosing the one that gives us the best scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e1417-1c60-47a9-89d7-4a36a84487f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(clf, X_train_over, y_train_over, cv=5, n_jobs=-1)\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719bc2a9-e82e-40c7-9a99-8fd3ff06e6f9",
   "metadata": {},
   "source": [
    "We create a dictionary \"params\" with the range of hyperparameters that we want to evaluate for our classifier. we check the scikit-learn documentation for predictor ideas on which hyperparameters to tune.\n",
    "\n",
    "The classifier we built is a pipeline with multiple steps so we include include the step name in the keys of your params dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8449c4-a433-494f-873a-86ad7c59ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"simpleimputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"randomforestclassifier__n_estimators\": range(25, 100, 25),\n",
    "    \"randomforestclassifier__max_depth\": range(10, 50, 10)\n",
    "}\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57922b27-6b1d-4352-8848-7e233354584b",
   "metadata": {},
   "source": [
    "Next we create a GridSearchCV named model that includes our classifier and hyperparameter grid. we to set cv to 5, n_jobs to -1, and verbose to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8550efa-4462-41d6-8f1a-9fdc8ae7bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(clf, param_grid=params, cv=5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671bd579-a3e2-42a7-9abc-524b6d6e4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting our model to the over-sampled training data.\n",
    "model.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde7fcfe-46a0-4e3a-833b-7a090d39d78f",
   "metadata": {},
   "source": [
    "We extract the cross-validation results from our model, and load them into a DataFrame named cv_results, to know which set of hyperparameters led to the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc68cbd-0877-4e08-bcbf-67592481e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(model.cv_results_)\n",
    "cv_results.sort_values(\"rank_test_score\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969ea08a-764c-4350-8694-d2ea1e735cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best hyperparameters\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3391f63-2480-492d-977c-1812e4f42e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model by testing the quality of our model by calculating accuracy scores for the training and test data.\n",
    "acc_train = model.score(X_train, y_train)\n",
    "acc_test = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Model Training Accuracy:\", round(acc_train, 4))\n",
    "print(\"Model Test Accuracy:\", round(acc_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2032243-ee1c-471c-983d-5606ddb07ebb",
   "metadata": {},
   "source": [
    "When dealing with imbalanced data, \"good\" accuracy scores alone don’t tell us much about model performance. Instead of just focusing on what the model got right or wrong, we should examine how its predictions differ across the two classes. To do this, let's plot a confusion matrix that shows how our best model performs on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d193324-b6a2-43f7-a173-deda2b5a7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b8d16a-958e-440b-807e-c8715c72b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a classification report for the model's performance on the test data and assigning it to class_report.\n",
    "class_report = classification_report(y_test, model.predict(X_test))\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abc0f74-9a94-44f0-89ff-4ebff485eff2",
   "metadata": {},
   "source": [
    "Creating a horizontal bar chart with the 10 most important features for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9cfa0f-9cad-4687-8f46-218173db997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names from training data\n",
    "features = X_train_over.columns\n",
    "\n",
    "# Extracting importances from model\n",
    "importances = model.best_estimator_.named_steps[\n",
    "    \"randomforestclassifier\"\n",
    "                                               ].feature_importances_\n",
    "\n",
    "# Creating a series with feature names and importances\n",
    "feat_imp = pd.Series(importances, index=features).sort_values()\n",
    "\n",
    "# Plot 10 most important features\n",
    "feat_imp.tail(10).plot(kind=\"barh\")\n",
    "plt.xlabel(\"Gini Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f406c36a-4df2-4500-aa5f-3bd932b30042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model as a pickle file\n",
    "import pickle\n",
    "with open(\"model_poland.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa1cb75-de29-4f4f-8b39-1db1183e3a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (5910,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Company_ID\n",
       "37495    False\n",
       "37496    False\n",
       "37497    False\n",
       "37498    False\n",
       "37499    False\n",
       "Name: class, dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from my_predictor_poland import make_predictions\n",
    "# Generate predictions\n",
    "y_test_pred = make_predictions(\n",
    "    data_filepath=r\"C:\\Users\\HP\\Desktop\\archive\\data.csv\",  # Use raw string\n",
    "    model_filepath=\"model_poland.pkl\"\n",
    ")\n",
    "print(\"predictions shape:\", y_test_pred.shape)\n",
    "y_test_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbb5d08-4077-4fea-9c31-1282b88a5cfb",
   "metadata": {},
   "source": [
    "I hope the analysis can help any data science enthusiast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80754d8-dbfb-456d-8f19-b4e64ee17277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
